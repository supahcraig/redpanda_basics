# S3 Connector

We have a guide in our docs, it is wildly outdated.
https://docs.redpanda.com/docs/deploy/deployment-option/cloud/managed-connectors/create-s3-sink-connector/#choose-connector-type

## S3 Bucket Policy

For starters, the policy as-written won't work, I had to modify it as follows:

```
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "Statement1",
			"Principal": "*",
			"Effect": "Allow",
			"Action": [
				"s3:GetObject",
				"s3:PutObject",
				"s3:AbortMultipartUpload",
				"s3:ListMultipartUploadParts",
				"s3:ListBucketMultipartUploads"
			],
			"Resource": [
				"arn:aws:s3:::cnelson-bucket/*",
				"arn:aws:s3:::cnelson-bucket"
			]
		}
	]
}
```

Specifically I needed to add the Principal line and the resource line for the bucket by itself (not including the `*/` suffix.   There is probably a way to further restrict that principal.

Then I needed to stop blocking public access.   If there is a subset of permissions, I didn't bother trying to find it.

## Example config

This is the config I went with:

```
{
    "name": "cnelson-s3",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "value.converter": "org.apache.kafka.connect.storage.StringConverter",
    "file.name.prefix": "from_connector/",
    "topics": "s3_topic",
    "aws.s3.bucket.name": "cnelson-bucket",
    "aws.access.key.id": "my_aws_access_key_id",
    "aws.secret.access.key": "my_aws_secret_key",
    "aws.s3.region": "us-east-2",
    "connector.class": "com.redpanda.kafka.connect.s3.S3SinkConnector"
}
```

## Operations

As soon as you start publishing messages to the topic, you should be able to see them in the console.   The connector should start (multipart?) copying them up to s3.  This implies there is consumer....which there is, named `connect-<topic name>`.   

TODO:  need to understand how auth/acl's work with this consumer group.   And why I didn't need to specify any credentials here but I did on the Postgres connector.
