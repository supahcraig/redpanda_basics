input:
  generate:
    interval: '@every 5s'
    mapping: 'root = {}'

pipeline:
  processors:
    - cache:
        resource: cached_pgstate
        operator: get
        key: content_notification_id

    - catch:
      - mapping: 'root.hwm_id = -1'

    - log:
        message: 'Using cached value: ${! content() }'

    - sql_raw:
        driver: postgres
        dsn: postgres://admin:admin@localhost:5432/inventory?sslmode=disable

        query: 'select * from content_notification where id > $1'
        args_mapping: root = [ this.hwm_id ]

    - unarchive:
        format: json_array

output:
  broker:
    # send each processed message to each output sequentially
    pattern: fan_out_sequential
    outputs:
      #- stdout: {}

      - kafka_franz:
          seed_brokers:
            - localhost:19092
          topic: content_delta

      - processors:
          - mapping: |
              root.hwm_id = json("id").from_all().max()
        cache:
          target: cached_pgstate
          key: content_notification_id
          max_in_flight: 1

cache_resources:
  - label: cached_pgstate
    multilevel: [ inmem, pgstate ]

  - label: inmem
    memory:
      compaction_interval: ''

  - label: pgstate
    sql:
      driver: postgres
      dsn: postgres://admin:admin@localhost:5432/inventory?sslmode=disable
      table: rpcn_hwm_state
      key_column: key
      value_column: val
      set_suffix: ON CONFLICT(key) DO UPDATE SET val=excluded.val
      init_statement: |
        CREATE TABLE IF NOT EXISTS rpcn_hwm_state (
          key bytea PRIMARY KEY,
          val jsonb
        );
